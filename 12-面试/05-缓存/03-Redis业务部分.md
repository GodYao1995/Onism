[TOC]

## Redis业务部分

#### 问题 2：在海量Key中如何找出某些固定开头的Key？

1.  可以使用 keys 命令，支持pattter模式，
2.  但是由于Redis单线程处理机制，数据量太大的话会导致线程阻塞，影响服务的提供，所以不是推荐使用keys
3.  推荐使用 scan 命令，他可以无阻塞的提取指定模式的Key列表，但是有一定几率重复Key，不过可以手动去重

#### 问题 3：Redis如何实现异步消息队列？

1.  通过Redis的List结构，以及rpush、lpop命令可以是实现异步队列，
2.  当里面没有数据的时候,lpop无法获取到数据,lpop空轮询造成客户端CPU压力增大和Redis的QPS升高,所以需要sleep
3.  sleep增加了延迟，鉴于此 blpop 命令可以阻塞读，在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来，降低延迟

**注意** 

1.  如果长时间没有数据，那么服务器就会断开连接，blpop会抛出异常，所以程序中需要捕获异常如果需要可以重试
2.  Redis实现的异步消息队列不是完全可靠消息队列，可以使用专业MQ解决
3.  异步消息队列不支持多播【发布订阅模式支持】

#### 问题 6：发布订阅模式Pub/Sub?

1.  发布订阅模式实际上是生产者消费者模型
2.  支持消息多播，中间件负责将消息复制到多个消息队列，每个消息队列由相应的消费组进行消费
3.  支持单个频道和多个频道发布订阅
4.  但是Redis的发布订阅模式不是可靠的，当消费者下线，消息就会丢失，并且宕机后消息无法持久化

#### 问题 9：Redis常见性能问题和解决方案？

1.  Master不要做持久化的工作，如果数据比较重要Slave开启AOF每秒同步
2.  最好在同一个局域网内
3.  主从复制采用链表的形式 master——>slave——>slave
4.  避免在压力很大的主库上增加从库

#### 问题10：多个系统对同Redis同一Key操作？

1.  会造成数据的错误【假设你需要的顺序的A B C三个系统操作】
2.  使用分布式锁ZooKeeper，每个系统必须获取锁才能去操作，并且同时一刻只能有一个系统获取到锁

#### 问题 4：大量Key需要设置同一时间过期，要注意什么？

1.  大量Key同时过期可能造成Redis卡顿，并且如果同时大量的访问进入，严重的话可能造成缓存雪崩
2.  一般情况下，可以给需要过期的Key设置随机的过期时间，尽量不要让大量的Key同一时间过期

#### 问题 6：数据库与缓存数据一致性问题？

1.  如果是MySQL数据源改变，那么我们在MySQL更新完毕后可以对Redis进行主动的更新
2.  可以对Redis的数据进行失效处理，去请求数据源，然后重新更新到缓存

数据还是不一致？

1.  如果是业务对耗时不明显，那么可以重试几次
2.  异步任务去更新，最终能达到数据一致就行

延时双删

~~~go
redis.del(key)
db.Update(data)
time.Sleep(1)  
redis.del(key)   
// 再删除一次的意思是防止B事务，在A事务还没有更新完数据库又去读取了一次，
// 造成缓存再次是旧的数据
~~~



#### 问题 7：Redis的缓存雪崩、穿透、击穿了解么？有什么异同点？分别怎么解决？

1. 缓存雪崩

    *   应用的缓存数据一般都是定时任务去刷新或者查不到再去更新

    *   假设某种情况下大面积【大量】Key同时失效，造成Redis无数据，此时大量的请求进来造成压力全部打到数据库
        *   要么造成业务延迟
        *   严重数据库直接宕机
    *   解决方案
        *   设置Key的时候随机给上他们的过期时间，保证不在同一时间大面积失效
        *   设置热点数据永不过期，需要更新的时候更新就好了

2. 缓存穿透

    *   不断请求数据缓存和数据库中都没有的数据，导致大量请求直接穿透到数据库，造成数据库压力过大
        *   比如请求id为负的记录或者id不存在于数据库的记录
        *   或者分页的参数不在数据库范围
    *   解决方案
        *   一定要在接口层做严格的参数校验、用户权限校验
        *   还可以做接口请求的频率限制【避免恶意请求】
        *   或者返回信息提示用户稍后重试，或者**设置Key的默认值Null**、位置错误、【友好的方案】
        *   高级方案【布隆过滤器】【快速判断出你这个Key是否在数据库中存在】

3. 缓存击穿

    *   指一个热点Key一直被大量请求，一旦Key失效，大量请求落到数据库上，造成数据库压力增大
    *   解决方案【设置热点数据不过期并且加上互斥锁】

4. 如何做避免以上的情况尽可能的不发生？

    *   做好Redis的高可用
    *   做好限流【牺牲部分用户】随机的返回一些请求
    *   服务降级【牺牲业务体验】停止某不重要的服务
    *   持久化重启恢复数据

    

#### 问题 8：MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据？

Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略



#### 问题 9：常规的缓存+数据库读写模式？

1. 模式

    *   先读缓存，如果没有再去读数据库，然后写缓存，最后返回响应
    *   更新的时候先更新数据库，然后删除缓存

2. 为什么是删除缓存，而不是更新

    *   缓存的数据组成不一定就是更新的数据库的数据，可能是复杂的计算后的结果
    *   涉及更新数据的缓存不一定是请求量非常高的数据，删除后当有请求来再去更新，是一种懒加载的方式

    

#### 问题10：缓存与数据库双存储双写，如何解决数据不一致性问题？

只有在对一个数据在高并发的进行读写的时候，才可能会出现这种问题

1.  方案1【初级不一致解决】
    *   先修改数据库
    *   再去删除缓存——>如果删除失败——>造成数据库是新数据——>缓存是脏数据
2.  方案2【比较复杂的数据不一致解决】
    *   先删除缓存
    *   再去修改数据库——>如果此时有请求来查发现缓存没有数据——>去查数据库——>此时是脏数据
3.  高并发下终极解决办法【单个线程处理操作的队列】
    *   删除缓存
    *   然后去更新数据库【入队列】
    *   读操作来到【可以设置超时时间】
        *   发现缓存无数据——>数据库请求【入队列】——>更新缓存【入队列】
    *   结果就是所有的操作串型化执行，保证了数据一致性，但是降低了系统的吞吐量


#### 问题15：Redis集群Hash槽？数据库选择？

1.  16384个
2.  默认都是0号数据库



#### 问题16：zset如何依据两个字段排序？

1.  热度+时间作为排序字段， 这种特点的场景，解决方法是组装一个浮点数，整数部分 是热度的值，小数部分是时间
2.  redis 里面精度应该是小数 6 位，所以不 能把整个日期作为小数部分

#### big key

1.  例如：string长度大于10K，list长度大于10240认为是big bigkeys
2.  以hash类型举例来说，对于field过多的场景，可以根据field进行hash取模，生成一个新的key

~~~
hash_key:{filed1:value, filed2:value, filed3:value ...}，可以hash取模后形成如下key:value形式
hash_key:mod1:{filed1:value}
hash_key:mod2:{filed2:value}
hash_key:mod3:{filed3:value}
~~~

3.  string类型的big key，如文章正文，建议不要存入redis，用文档型数据库MongoDB代替或者直接缓存到CDN上

**拓展**
通常来说找到redis中的big key有如下几种方法

1.  redis-cli自带--bigkeys，例如：redis-cli -h -a --bigkeys
2.  获取生产Redis的rdb文件，通过rdbtools分析rdb生成csv文件，再导入MySQL或其他数据库中进行分析统计，根据size_in_bytes统计bigkey
3.  通过python脚本，迭代scan key，每次scan 1000，对扫描出来的key进行类型判断，例如：string长度大于10K，list长度大于10240认为是big bigkeys
4.  其他第三方工具，例如：redis-rdb-cli
    地址：https://github.com/leonchen83/redis-rdb-cli

#### 问题9：key如何设置

1.  避免bigkey

2.  分级设置key

3.  加上项目前缀

4.  设置过期时间

5.  见明知意 